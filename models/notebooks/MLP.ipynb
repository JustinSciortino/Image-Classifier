{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg_Aq0VMouV2",
    "outputId": "e14a8bc5-1c3a-4b83-d5f5-e592f6667b14"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "TRAINED_MODEL_DIR = \"trained_models\"\n",
    "if not os.path.exists(TRAINED_MODEL_DIR):\n",
    "    os.makedirs(TRAINED_MODEL_DIR)\n",
    "\n",
    "\"\"\"\n",
    "Useful sources for information:\n",
    "https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch\n",
    "https://www.datacamp.com/tutorial/multilayer-perceptrons-in-machine-learning\n",
    "https://medium.com/deep-learning-study-notes/multi-layer-perceptron-mlp-in-pytorch-21ea46d50e62\n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, train_tensors, train_labels, test_tensors, test_labels, num_features=512, hidden_size=512, output_size=10, learning_rate=0.001, momentum=0.9, batch_size=128, epochs=30, layers=3):\n",
    "\n",
    "        #* Hyperparameters\n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size \n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "        #* Metrics used to be saved/loaded\n",
    "        self.training_time = 0\n",
    "        self.GPU_mememory_allocated = 0\n",
    "        self.GPU_max_memory_allocated = 0\n",
    "        self.CPU_memory_usage = 0\n",
    "\n",
    "        #* MLP architecture with different number of layers\n",
    "        if layers == 3:\n",
    "          self.model = nn.Sequential( \n",
    "              nn.Linear(num_features, hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, hidden_size),\n",
    "              nn.BatchNorm1d(hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, output_size)\n",
    "          ).to(device)\n",
    "\n",
    "        elif layers == 2:\n",
    "          self.model = nn.Sequential(\n",
    "              nn.Linear(num_features, hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, output_size)\n",
    "          ).to(device)\n",
    "\n",
    "        elif layers == 4:\n",
    "          self.model = nn.Sequential( \n",
    "              nn.Linear(num_features, hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, hidden_size),\n",
    "              nn.BatchNorm1d(hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, hidden_size),\n",
    "              nn.BatchNorm1d(hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, output_size)\n",
    "          ).to(device)\n",
    "\n",
    "        elif layers == 6:\n",
    "          self.model = nn.Sequential( \n",
    "              nn.Linear(num_features, hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, hidden_size),\n",
    "              nn.BatchNorm1d(hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, hidden_size),\n",
    "              nn.BatchNorm1d(hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, hidden_size),\n",
    "              nn.BatchNorm1d(hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, hidden_size),\n",
    "              nn.BatchNorm1d(hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, output_size)\n",
    "          ).to(device)\n",
    "\n",
    "\n",
    "        #* Loss function and optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "        self.train_tensors = train_tensors.to(device)\n",
    "        self.train_labels = train_labels.to(device)\n",
    "        self.test_tensors = test_tensors.to(device)\n",
    "        self.test_labels = test_labels.to(device)\n",
    "\n",
    "        #* Create DataLoaders from the tensors\n",
    "        train_dataset = TensorDataset(train_tensors, train_labels)\n",
    "        test_dataset = TensorDataset(test_tensors, test_labels)\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    #* Train model for one epoch\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in self.train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X_batch)\n",
    "            loss = self.criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    #* Evaluate the model on the test set and return the metrics\n",
    "    def evaluate(self):\n",
    "        start_time = time.time()\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in self.test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = self.model(X_batch)\n",
    "                loss = self.criterion(outputs, y_batch)\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "        #* Metrics\n",
    "        evaluation_time = time.time() - start_time\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
    "        recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "        return total_loss / len(self.test_loader), accuracy, conf_matrix, precision, recall, f1, evaluation_time\n",
    "    \n",
    "    #* Train the model for the specified number of epochs in the constructor\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss = self.train_epoch()\n",
    "        self.training_time = time.time() - start_time\n",
    "\n",
    "    #* Save the model to a file\n",
    "    def save_model(self, filename=\"mlp_model.pth\"):\n",
    "        filepath = os.path.join(TRAINED_MODEL_DIR, filename)\n",
    "        torch.save({\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"training_time\": self.training_time,\n",
    "            \"GPU_mememory_allocated\": self.GPU_mememory_allocated,\n",
    "            \"GPU_max_memory_allocated\": self.GPU_max_memory_allocated,\n",
    "            \"CPU_memory_usage\": self.CPU_memory_usage\n",
    "        }, filepath)\n",
    "        print(f\"Model and metadata saved to {filepath}\")\n",
    "\n",
    "    #* Load the model from a file\n",
    "    def load_model(self, filename=\"mlp_model.pth\"):\n",
    "        filepath = os.path.join(TRAINED_MODEL_DIR, filename)\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.training_time = checkpoint.get(\"training_time\", 0)\n",
    "        self.GPU_mememory_allocated = checkpoint.get(\"GPU_mememory_allocated\", 0)\n",
    "        self.GPU_max_memory_allocated = checkpoint.get(\"GPU_max_memory_allocated\", 0)\n",
    "        self.CPU_memory_usage = checkpoint.get(\"CPU_memory_usage\", 0)\n",
    "        self.model.eval()\n",
    "        print(f\"Model loaded from {filepath}, Training Time: {self.training_time:.2f} seconds\")\n",
    "\n",
    "    #* Get the memory usage of the model for both CPU and GPU\n",
    "    def get_memory_usage(self):\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e6:.2f} MB\")\n",
    "            print(f\"GPU Max Memory Allocated: {torch.cuda.max_memory_allocated() / 1e6:.2f} MB\")\n",
    "            self.GPU_mememory_allocated = torch.cuda.memory_allocated() / 1e6\n",
    "            self.GPU_max_memory_allocated = torch.cuda.max_memory_allocated() / 1e6\n",
    "        else:\n",
    "            process = psutil.Process(os.getpid())\n",
    "            print(f\"CPU Memory Usage: {process.memory_info().rss / 1e6:.2f} MB\")\n",
    "            self.CPU_memory_usage = process.memory_info().rss / 1e6\n",
    "\n",
    "    #* Get the memory usage of the model for both CPU and GPU and the training time\n",
    "    def get_mememory_training_data(self):\n",
    "        return self.GPU_mememory_allocated, self.GPU_max_memory_allocated, self.CPU_memory_usage, self.training_time\n",
    "\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    TRAINED_MODEL_DIR = \"trained_models\"\n",
    "    model_path = os.path.join(TRAINED_MODEL_DIR, filename)\n",
    "    data = np.load(model_path)\n",
    "    return (data['train_features'], data['train_labels'],\n",
    "            data['test_features'], data['test_labels'],\n",
    "            data['train_features_pca'], data['test_features_pca'])\n",
    "\n",
    "def load_tensors():\n",
    "    TRAINED_MODEL_DIR = \"trained_models\"\n",
    "    model_path = os.path.join(TRAINED_MODEL_DIR, \"cifar10_tensors.pt\")\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        data = torch.load(model_path)\n",
    "        print(f\"Tensors loaded from {model_path}\")\n",
    "        return (\n",
    "            data['train_features_tensors'],\n",
    "            data['train_labels_tensors'],\n",
    "            data['test_features_tensors'],\n",
    "            data['test_labels_tensors'],\n",
    "            data['train_features_pca_tensors'],\n",
    "            data['test_features_pca_tensors']\n",
    "        )\n",
    "    else:\n",
    "        print(f\"File {model_path} does not exist.\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "  file_path = os.path.join(TRAINED_MODEL_DIR, \"cifar10_data.npz\")\n",
    "  train_loader, test_loader = [None] * 2\n",
    "  train_features, train_labels, test_features, test_labels, train_features_pca, test_features_pca, train_loader, test_loader = [None] * 8\n",
    "  train_features_tensors, train_labels_tensors, test_features_tensors, test_labels_tensors, train_features_tensors_pca, test_features_tensors_pca = [None] * 6\n",
    "\n",
    "  print(\"Loading CIFAR-10 npz file...\")\n",
    "  train_features, train_labels, test_features, test_labels, train_features_pca, test_features_pca = load_data(filename=\"cifar10_data.npz\")\n",
    "\n",
    "  print(\"Loading CIFAR-10 tensors file...\")\n",
    "  train_features_tensors, train_labels_tensors, test_features_tensors, test_labels_tensors, train_features_tensors_pca, test_features_tensors_pca = load_tensors()\n",
    "\n",
    "  print(\"\\nEvaluating MLP Model without PCA reduction (512 Features)\")\n",
    "  batches = [128]\n",
    "  learning_rates = [0.001]\n",
    "  epochs = [30]\n",
    "  hidden_sizes = [256, 512, 1024]\n",
    "  layers = [3, 2, 4, 6]\n",
    "\n",
    "  for batch_size in batches:\n",
    "    for learning_rate in learning_rates:\n",
    "      for epoch in epochs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "          for layer in layers:\n",
    "\n",
    "            print(f\"\\nEvaluating MLP Model with batch_size={batch_size}, learning_rate={learning_rate}, epochs={epoch}, hidden_size={hidden_size}, number of layers={layer}, 512 features\")\n",
    "            file_path_mlp = os.path.join(f\"MLP_HiddenSize{hidden_size}_{layer}Layers.pth\")\n",
    "\n",
    "            if not os.path.exists(os.path.join(TRAINED_MODEL_DIR, file_path_mlp)):\n",
    "                print(\"Training MLP Model\")\n",
    "                mlp = MLP(\n",
    "                    train_tensors=train_features_tensors,\n",
    "                    train_labels=train_labels_tensors,\n",
    "                    test_tensors=test_features_tensors,\n",
    "                    test_labels=test_labels_tensors,\n",
    "                    num_features=512,\n",
    "                    hidden_size=hidden_size,\n",
    "                    learning_rate=learning_rate,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epoch,\n",
    "                    layers=layer\n",
    "                )\n",
    "                mlp.train()\n",
    "                mlp.get_memory_usage()\n",
    "                mlp.save_model(filename=file_path_mlp)\n",
    "                _, accuracy, conf_matrix, precision, recall, f1, evaluate_time = mlp.evaluate()\n",
    "                GPU_mememory_allocated, GPU_max_memory_allocated, CPU_memory_usage, training_time = mlp.get_mememory_training_data()\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1 Score: {f1}\")\n",
    "                print(f\"Evaluation Time: {evaluate_time} seconds\")\n",
    "                print(f\"Training Time: {training_time} seconds\")\n",
    "                print(f\"GPU Memory Allocated: {GPU_mememory_allocated} MB\")\n",
    "                print(f\"GPU Max Memory Allocated: {GPU_max_memory_allocated} MB\")\n",
    "                print(f\"CPU Memory Usage: {CPU_memory_usage} MB\")\n",
    "                if layer == 3:\n",
    "                    print(f\"Three-layer MLP model\")\n",
    "                elif layer == 2:\n",
    "                    print(f\"Two-layer MLP model\")\n",
    "                elif layer == 4:\n",
    "                    print(f\"Four-layer MLP model\")\n",
    "                else:\n",
    "                    print(f\"Six-layer MLP model\")\n",
    "\n",
    "            else:\n",
    "                print(\"Loading saved MLP Model\")\n",
    "                mlp = MLP(\n",
    "                    train_tensors=train_features_tensors,\n",
    "                    train_labels=train_labels_tensors,\n",
    "                    test_tensors=test_features_tensors,\n",
    "                    test_labels=test_labels_tensors,\n",
    "                    num_features=512,\n",
    "                    hidden_size=hidden_size,\n",
    "                    learning_rate=learning_rate,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epoch,\n",
    "                    layers=layer\n",
    "                )\n",
    "                mlp.load_model(filename=file_path_mlp)\n",
    "                _, accuracy, conf_matrix, precision, recall, f1, evaluate_time = mlp.evaluate()\n",
    "                GPU_mememory_allocated, GPU_max_memory_allocated, CPU_memory_usage, training_time = mlp.get_mememory_training_data()\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1 Score: {f1}\")\n",
    "                print(f\"Evaluation Time: {evaluate_time} seconds\")\n",
    "                print(f\"Training Time: {training_time} seconds\")\n",
    "                print(f\"GPU Memory Allocated: {GPU_mememory_allocated} MB\")\n",
    "                print(f\"GPU Max Memory Allocated: {GPU_max_memory_allocated} MB\")\n",
    "                print(f\"CPU Memory Usage: {CPU_memory_usage} MB\")\n",
    "                if layer == 3:\n",
    "                    print(f\"Three-layer MLP model\")\n",
    "                elif layer == 2:\n",
    "                    print(f\"Two-layer MLP model\")\n",
    "                elif layer == 4:\n",
    "                    print(f\"Four-layer MLP model\")\n",
    "                else:\n",
    "                    print(f\"Six-layer MLP model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PYfTZw_LG7u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
